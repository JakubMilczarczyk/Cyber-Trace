{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6300430c-f257-49df-a476-dc125524deed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Project Cyber-Trace: Bronze Layer Ingestion\n",
    "**Author:** Jakub Milczarczyk  \n",
    "**Pipeline Type:** Streaming Ingestion (Medallion Architecture)\n",
    "\n",
    "## Objective\n",
    "Ingest raw security logs (OTRF/Mordor dataset) from **Azure Data Lake Gen2 (ADLS)** into the Bronze Layer (Delta Lake) ensuring schema resilience and data durability.\n",
    "\n",
    "## Technical Highlights\n",
    "* **Auto Loader (cloudFiles):** Utilized for scalable, incremental ingestion without listing overhead.\n",
    "* **Schema Evolution:** Enabled (`mergeSchema`) to handle dynamic changes in JSON log structures without breaking the pipeline.\n",
    "* **Security:** Credentials retrieved via **Azure Key Vault** (Secret Scopes) - zero hardcoded secrets.\n",
    "* **Quality Gate:** \"Bad Records\" are automatically quarantined to `_quarantine` path for retrospective analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c9f811d-6582-4feb-8922-2e75bbacd765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: CONFIGURATION & AUTHENTICATION\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Secure Authentication\n",
    "from src.config import setup_authentication, ProjectConfig, Paths\n",
    "from src.logger import get_logger\n",
    "\n",
    "logger = get_logger(\"BronzeIngestion\")\n",
    "\n",
    "setup_authentication(spark, dbutils)\n",
    "\n",
    "# 2. Path Definitions\n",
    "base_path       = ProjectConfig.get_base_path()\n",
    "raw_logs_path   = Paths.RAW_LOGS\n",
    "schema_path     = Paths.SCHEMA\n",
    "checkpoint_path_bronze = Paths.CHECKPOINT_BRONZE\n",
    "quarantine_path = Paths.QUARANTINE\n",
    "\n",
    "logger.info(f\"CONFIG: Paths set. Ingestion target: {raw_logs_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4336905c-ea88-42fe-88a0-c84c8eb1dfe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Ingestion Pipeline (Auto Loader)\n",
    "**Objective:** ingest raw JSON logs efficiently and robustly.\n",
    "\n",
    "**Technology Stack:**\n",
    "* **Databricks Auto Loader (`cloudFiles`):** An optimized file source that detects new files as they arrive in ADLS without listing the entire directory (solving the \"S3/ADLS listing\" performance bottleneck).\n",
    "* **Schema Evolution:** The pipeline is configured to automatically detect and adapt to changes in the log structure (e.g., new fields in JSON events) using `schema_path`.\n",
    "* **Checkpointing:** Ensures fault tolerance. If the cluster crashes, the stream resumes exactly where it left off.\n",
    "\n",
    "**Output:**\n",
    "The stream writes to an **Delta Lake** (`delta` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886b89d4-b714-41d9-a444-d6b5f0e1d56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: DATA INGESTION PIPELINE\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define the Stream (Auto Loader)\n",
    "logger.info(f\"SYSTEM: Initializing Auto Loader from {raw_logs_path}...\")\n",
    "df_stream = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", schema_path)\n",
    "    .option(\"badRecordsPath\", quarantine_path)\n",
    "    .load(raw_logs_path)\n",
    ")\n",
    "\n",
    "# 2. Run the Stream (In-Memory for testing)\n",
    "bronze_table_name = \"bronze_mordor_logs_v2\"\n",
    "\n",
    "query = (df_stream.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path_bronze + \"_v2\")\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .table(bronze_table_name)\n",
    ")\n",
    "\n",
    "logger.info(\"SYSTEM: Stream started in background...\")\n",
    "logger.info(\"SYSTEM: Stream finished processing. Data is durable in Delta Lake.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ccd1e9e-78b9-42cb-8a86-0cdca30de9c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Bad Records Validation\n",
    "\n",
    "**Objective:** Find and quarantine wrong records\n",
    "\n",
    "**Monitoring Quality:** Checks for records rejected by Auto Loader due to schema mismatch.\n",
    "\n",
    "**Output:** The Stream writes founded records to _quarantine directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7433e606-9fa2-43d9-8dac-11b9096c8c68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 3: BAD RECORDS VALIDATION\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define the Stream (Bad Records)\n",
    "logger.info(f\"Checking quarantine path: {quarantine_path}\")\n",
    "\n",
    "quarantine_schema = \"path STRING, record STRING, reason STRING\"\n",
    "\n",
    "bad_records_df = (spark.read\n",
    "    .schema(quarantine_schema)\n",
    "    .option(\"recursiveFileLookup\", \"true\")\n",
    "    .json(quarantine_path)\n",
    ")\n",
    "\n",
    "logger.info(\"SYSTEM: Data checked.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8236b881-fd06-4739-9b83-19169ea14a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f22408-7a90-412c-893f-8628c62e3ef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_mordor_logs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
