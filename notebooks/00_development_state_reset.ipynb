{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f8bfeba-5b22-4eac-883e-08feaccf982d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Development State Reset (⚠️ DEV ONLY)\n",
    "Objective: To simulate a \"fresh start\" of the ingestion pipeline during the prototyping phase.\n",
    "\n",
    "Context: Spark Structured Streaming maintains the state of processed files in a Checkpoint location. To re-process the same dataset or test configuration changes, we must clear this metadata.\n",
    "\n",
    "Warning: This step deletes the checkpoint history. In a Production environment, this cell would be disabled or removed to prevent data duplication and loss of processing history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33238325-4b6d-4492-a7a3-5a2b33978ef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: CONFIGURATION & AUTHENTICATION\n",
    "# Environment setup - Safe to run in any environment\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Secure Authentication\n",
    "from src.config import setup_authentication, ProjectConfig, Paths\n",
    "\n",
    "setup_authentication(spark, dbutils)\n",
    "\n",
    "# 2. Path Definitions\n",
    "base_path       = ProjectConfig.get_base_path()\n",
    "raw_logs_path   = Paths.RAW_LOGS\n",
    "schema_path     = Paths.SCHEMA\n",
    "checkpoint_path_bronze = Paths.CHECKPOINT_BRONZE\n",
    "quarantine_path = Paths.QUARANTINE\n",
    "\n",
    "print(f\"CONFIG: Paths set. Ingestion target: {raw_logs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb9319b8-9bc9-456f-ae5d-8588429d06cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: ENVIRONMENT RESET (⚠️ DEV ONLY ⚠️)\n",
    "# Executes a cleanup to restart streaming from scratch.\n",
    "# DO NOT RUN THIS IN PRODUCTION or you will lose processing history!\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"MAINTENANCE: Cleaning up checkpoints and schemas for a fresh start...\")\n",
    "\n",
    "# Remove checkpoints (resets stream offset to zero)\n",
    "dbutils.fs.rm(checkpoint_path_bronze, recurse=True)\n",
    "\n",
    "# Optional: Remove inferred schema if you want to re-learn column types\n",
    "dbutils.fs.rm(schema_path, recurse=True)\n",
    "\n",
    "# Resets quarantine folder and rebuild it\n",
    "dbutils.fs.rm(quarantine_path, recurse=True)\n",
    "dbutils.fs.mkdirs(quarantine_path)\n",
    "\n",
    "print(\"MAINTENANCE: Environment clean. Ready for fresh ingestion.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_development_state_reset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
